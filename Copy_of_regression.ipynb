{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwGFZiTEsCLXqoaoMGOEcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pwmuskan/pw/blob/main/Copy_of_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        "It attempts to determine the strength and characteristics of the relationship between one independent variable(X) and other dependent variable(Y)\n",
        "\n",
        "Independent variable (X) ‚Äì Also known as the predictor or explanatory variable.\n",
        "\n",
        "Dependent variable (Y) ‚Äì Also known as the response or target variable."
      ],
      "metadata": {
        "id": "IOOvMzd9U14F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Linearity: The relationship between X and Y should be linear.\n",
        "\n",
        "Independence: Observations should be independent of each other.\n",
        "\n",
        "Homoscedasticity: Constant variance of residuals (errors).\n",
        "\n",
        "Normality of Residuals: The residuals should be normally distributed."
      ],
      "metadata": {
        "id": "dpzuGBFiVjph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "The coefficient\n",
        "ùëö\n",
        "m represents the rate of change of Y with respect to X. It tells us how much\n",
        "ùëå changes for a one-unit increase in\n",
        "ùëã\n",
        ".\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "If\n",
        "m>0 ‚Üí Positive relationship (as\n",
        "ùëã\n",
        " increases,\n",
        "ùëå\n",
        "also increases).\n",
        "\n",
        "If\n",
        "m<0 ‚Üí Negative relationship (as\n",
        "ùëã\n",
        " increases,\n",
        "ùëå\n",
        " decreases).\n",
        "\n",
        "If\n",
        "m=0 ‚Üí No relationship (the line is horizontal, meaning\n",
        "ùëå\n",
        " is constant for all values of\n",
        "ùëã\n",
        ")."
      ],
      "metadata": {
        "id": "OpGUpQy2V0dY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does the intercept c represent in the equation Y=mX+c?\n",
        "\n",
        "The intercept\n",
        "ùëê\n",
        "c represents the value of\n",
        "ùëå\n",
        " when\n",
        "ùëã\n",
        "=\n",
        "0\n",
        ". It is the point where the regression line crosses the Y-axis.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "It shows the baseline value of\n",
        "ùëå\n",
        " when no independent variable is present.\n",
        "\n",
        "It may not always have a real-world meaning (especially when\n",
        "ùëã\n",
        "=\n",
        "0\n",
        " is not a possible or relevant value).\n"
      ],
      "metadata": {
        "id": "RO8j4CQsWZ3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        " The formula for calculating\n",
        "ùëö\n",
        "m (also called the regression coefficient) is:\n",
        "\n",
        "m=\n",
        "n‚àë(X\n",
        "i\n",
        "‚Äã\n",
        " Y\n",
        "i\n",
        "‚Äã\n",
        " )‚àí‚àëX\n",
        "i\n",
        "‚Äã\n",
        " ‚àëY\n",
        "i/n‚àëX\n",
        "i\n",
        "2\n",
        "‚Äã\n",
        " ‚àí(‚àëX\n",
        "i\n",
        "‚Äã\n",
        " )\n",
        "2\n",
        "\n",
        "where:\n",
        "\n",
        "n = Number of data points\n",
        "\n",
        "X\n",
        "i\n",
        "‚Äã\n",
        " ,Y\n",
        "i\n",
        "‚Äã\n",
        "  = Individual data points\n",
        "\n",
        "‚àëX\n",
        "i\n",
        "‚Äã = Sum of all\n",
        "X values\n",
        "\n",
        "‚àëY\n",
        "i\n",
        "‚Äã= Sum of all\n",
        "Y values\n",
        "\n",
        "‚àëX\n",
        "i\n",
        "‚Äã\n",
        " Y\n",
        "i\n",
        "‚Äã\n",
        "  = Sum of the product of corresponding\n",
        "X and\n",
        "Y values\n",
        "\n",
        "‚àëX\n",
        "i\n",
        "2\n",
        "  = Sum of the squares of\n",
        "X values"
      ],
      "metadata": {
        "id": "NM0-nz7NWyYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "The Least Squares Method is used in Simple Linear Regression to find the best-fitting line that minimizes the difference between the actual data points and the predicted values.\n",
        "\n",
        "In regression, we aim to model the relationship between independent variable (\n",
        "ùëã\n",
        ") and dependent variable (\n",
        "ùëå\n",
        "). However, the data points do not always lie perfectly on a straight line.\n",
        "\n",
        "The Least Squares Method helps us find the optimal slope (\n",
        "ùëö\n",
        ") and intercept (\n",
        "ùëê\n",
        ") by minimizing the sum of squared errors (residuals)."
      ],
      "metadata": {
        "id": "sYvgSU1MYgml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "\n",
        "In simple linear regression, the coefficient of determination, denoted as R¬≤, quantifies the proportion of variance in the dependent variable that is predictable from the independent variable. An R¬≤ value ranges between 0 and 1, where a value closer to 1 indicates that a greater proportion of variance is accounted for by the model, signifying a stronger explanatory power. Conversely, an R¬≤ value near 0 suggests that the model fails to explain much of the variance in the dependent variable.\n",
        "\n",
        "Mathematically, R¬≤ is calculated as the ratio of the regression sum of squares (SSR) to the total sum of squares (SSTO):\n",
        "\n",
        "R\n",
        "2\n",
        " =\n",
        "SSR/SSTO\n",
        "‚Äã\n",
        " =1‚àí\n",
        "SSE/SSTO\n",
        "‚Äã\n",
        "\n",
        "\n",
        "Here, SSE represents the error sum of squares."
      ],
      "metadata": {
        "id": "otWiJ_V3mLr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Multiple Linear Regression?\n",
        "\n",
        "Multiple Linear Regression (MLR) is a statistical technique that models the relationship between a dependent variable and two or more independent variables by fitting a linear equation to observed data.\n",
        "\n",
        " This method extends simple linear regression, which involves only one independent variable, to accommodate multiple predictors.\n",
        "\n",
        "\n",
        "The general form of the MLR equation is:\n",
        "\n",
        "ùë¶\n",
        "=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùë•\n",
        "1\n",
        "+\n",
        "ùõΩ\n",
        "2\n",
        "ùë•\n",
        "2\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "ùõΩ\n",
        "ùëù\n",
        "ùë•\n",
        "ùëù\n",
        "+\n",
        "ùúñ"
      ],
      "metadata": {
        "id": "GvtYndMJreJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "The primary distinction between simple and multiple linear regression lies in the number of independent variables utilized to predict the dependent variable. In simple linear regression, a single independent variable is used to predict the outcome of the dependent variable. Conversely, multiple linear regression employs two or more independent variables to forecast the dependent variable."
      ],
      "metadata": {
        "id": "VZWkj_fKsSkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "Linearity: There exists a linear relationship between the dependent variable and each of the independent variables. This can be assessed by examining scatterplots of the dependent variable against each predictor.\n",
        "\n",
        "No Multicollinearity: The independent variables are not highly correlated with each other. High multicollinearity can inflate the variance of coefficient estimates and make the model unstable. Variance Inflation Factor (VIF) is commonly used to detect multicollinearity.\n",
        "\n",
        "Independence of Errors: The residuals (errors) are independent of each other. This assumption is particularly important in time series data, where observations may be correlated over time. Durbin-Watson statistic is often used to test for autocorrelation in residuals.\n",
        "\n",
        "Homoscedasticity: The residuals have constant variance at every level of the independent variables. Plotting residuals versus fitted values can help detect heteroscedasticity, which appears as a systematic pattern in the spread of residuals.\n",
        "\n",
        "Normality of Errors: The residuals are normally distributed. This can be checked using a Q-Q plot or statistical tests like the Shapiro-Wilk test. Normality is essential for constructing confidence intervals and conducting hypothesis tests."
      ],
      "metadata": {
        "id": "kyFiPg64s6h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "Heteroscedasticity refers to a condition in regression analysis where the variance of the residuals (errors) is not constant across all levels of the independent variables. In other words, as the value of an independent variable changes, the spread or dispersion of the residuals changes as well. This violates one of the key assumptions of multiple linear regression, which assumes homoscedasticity‚Äîthat the residuals have constant variance.\n",
        "\n",
        "**Effects on Multiple Linear Regression:**\n",
        "\n",
        "Inefficient Estimates: Heteroscedasticity can lead to inefficient estimates of the regression coefficients. While the coefficients themselves remain unbiased, their standard errors become unreliable, which can affect hypothesis testing and the construction of confidence intervals.\n",
        "\n",
        "Invalid Statistical Tests: The presence of heteroscedasticity can result in p-values that are smaller than they should be. This occurs because heteroscedasticity increases the variance of the coefficient estimates, but standard regression techniques may not account for this increase. Consequently, this can lead to incorrect conclusions about the significance of predictors."
      ],
      "metadata": {
        "id": "VnMwpomEtYqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "To improve a model affected by multicollinearity, consider the following strategies:\n",
        "\n",
        "Increase Sample Size: Expanding the dataset can mitigate multicollinearity by providing more information, leading to more stable coefficient estimates.\n",
        "\n",
        "Center the Variables: Subtracting the mean from each predictor (centering) can reduce multicollinearity, especially when interaction terms are included in the model.\n",
        "\n",
        "Remove Highly Correlated Predictors: Identifying and excluding one of the highly correlated variables can simplify the model and alleviate multicollinearity issues.\n",
        "\n",
        "Combine Variables: Creating composite variables through techniques like Partial Least Squares (PLS) can consolidate information from correlated predictors, reducing multicollinearity.\n",
        "\n",
        "Use Regularization Methods: Applying techniques such as Ridge Regression or LASSO adds a penalty to the regression, shrinking coefficient estimates and effectively handling multicollinearity."
      ],
      "metadata": {
        "id": "ytBM_ru6t7T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "Dummy Coding (One-Hot Encoding): This method converts each category into a separate binary variable (dummy variable) that takes a value of 1 if the observation belongs to that category and 0 otherwise. For a categorical variable with\n",
        "ùëò\n",
        " levels,\n",
        "ùëò\n",
        "‚àí\n",
        "1\n",
        " dummy variables are created to avoid multicollinearity.\n",
        "\n",
        "Effect Coding: Similar to dummy coding, effect coding represents categories using binary variables. However, in effect coding, the reference category is assigned -1 instead of 0. This allows for comparing each category's effect to the overall mean rather than a specific reference category.\n",
        "\n",
        "Ordinal Encoding: Applicable when categorical variables have a natural order (e.g., low, medium, high). Each category is assigned a numerical value corresponding to its order. While simple, this method assumes equal spacing between categories, which may not always be appropriate.\n",
        "\n",
        "Polynomial Coding: Used for ordinal categorical variables, polynomial coding captures non-linear relationships by assigning orthogonal polynomial contrasts to the categories. This method is beneficial when the effect of the categorical variable is expected to follow a polynomial trend.\n",
        "\n",
        "Contrast Coding: A general term for coding schemes that compare specific groups or combinations of groups. Examples include simple coding, repeated coding, and others, each tailored to test particular hypotheses about group differences."
      ],
      "metadata": {
        "id": "8LsSIQWVvbfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "In multiple linear regression, interaction terms are used to model the combined effect of two or more independent variables on the dependent variable, beyond their individual contributions. An interaction occurs when the effect of one predictor variable on the outcome variable depends on the level of another predictor variable.\n",
        "\n",
        "Including interaction terms allows the regression model to capture more complex relationships between predictors. For instance, if you're studying the impact of study time and tutoring on student performance, an interaction term between study time and tutoring can reveal whether the effectiveness of study time varies depending on the presence of tutoring. This enables a more nuanced understanding of how variables work together to influence the outcome."
      ],
      "metadata": {
        "id": "-skGC3-pwit1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "In both simple and multiple linear regression models, the intercept represents the expected value of the dependent variable when all independent variables are equal to zero. However, the context and interpretability of the intercept can differ between the two models.\n",
        "\n",
        "Simple Linear Regression:\n",
        "\n",
        "In a simple linear regression model with one predictor variable\n",
        "X, the intercept\n",
        "Œ≤\n",
        "0\n",
        "‚Äã is the expected value of the dependent variable\n",
        "Y when\n",
        "X=0. Mathematically, the model is expressed as:\n",
        "\n",
        "Y=Œ≤\n",
        "0\n",
        "‚Äã\n",
        " +Œ≤\n",
        "1\n",
        "‚Äã\n",
        " X+Œµ\n",
        "\n",
        " In a multiple linear regression model with multiple predictor variables\n",
        "X\n",
        "1\n",
        "‚Äã\n",
        " ,X\n",
        "2\n",
        "‚Äã\n",
        " ,‚Ä¶,X\n",
        "n\n",
        "‚Äã\n",
        " , the intercept\n",
        "Œ≤\n",
        "0\n",
        "‚Äã\n",
        " represents the expected value of\n",
        "Y when all predictors are zero:\n",
        "\n",
        "Y=Œ≤\n",
        "0\n",
        "‚Äã\n",
        " +Œ≤\n",
        "1\n",
        "‚Äã\n",
        " X\n",
        "1\n",
        "‚Äã\n",
        " +Œ≤\n",
        "2\n",
        "‚Äã\n",
        " X\n",
        "2\n",
        "‚Äã\n",
        " +‚ãØ+Œ≤\n",
        "n\n",
        "‚Äã\n",
        " X\n",
        "n\n",
        "‚Äã\n",
        " +Œµ"
      ],
      "metadata": {
        "id": "uIKt2VwjytaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "In regression analysis, the slope of the regression line quantifies the relationship between the independent variable(s) and the dependent variable. Specifically, it represents the expected change in the dependent variable for a one-unit increase in the independent variable, assuming all other variables remain constant.\n",
        "\n",
        "Significance of the Slope:\n",
        "\n",
        "Direction of Association: A positive slope indicates a direct relationship, meaning that as the independent variable increases, the dependent variable also increases. Conversely, a negative slope signifies an inverse relationship, where an increase in the independent variable corresponds to a decrease in the dependent variable.\n",
        "\n",
        "Magnitude of Change: The absolute value of the slope reflects the rate of change in the dependent variable per unit change in the independent variable. A larger absolute value denotes a steeper relationship, indicating a more substantial impact of the independent variable on the dependent variable.\n",
        "\n",
        "Impact on Predictions:\n",
        "\n",
        "The slope is integral to the regression equation, typically expressed as:\n",
        "\n",
        "Y\n",
        "^\n",
        " =Œ≤\n",
        "0\n",
        "‚Äã\n",
        " +Œ≤\n",
        "1\n",
        "‚Äã\n",
        " X\n",
        "\n",
        "Here,\n",
        "Y\n",
        "^\n",
        "  is the predicted value of the dependent variable,\n",
        "Œ≤ 0\n",
        " is the intercept,\n",
        "Œ≤\n",
        "1\n",
        "  is the slope, and\n",
        "X is the independent variable.\n",
        "\n",
        "When making predictions:\n",
        "\n",
        "Positive Slope: An increase in\n",
        "X leads to an increase in\n",
        "Y\n",
        "^\n",
        " .\n",
        "\n",
        "Negative Slope: An increase in\n",
        "X results in a decrease in\n",
        "Y\n",
        "^\n",
        " .\n",
        "\n",
        "The magnitude of the slope determines the sensitivity of the predictions to changes in the independent variable. A steeper slope implies that small changes in\n",
        "X will result in larger changes in\n",
        "Y\n",
        "^\n",
        " , while a gentler slope suggests that\n",
        "Y\n",
        "^\n",
        "  is less responsive to variations in\n",
        "X.\n",
        "\n",
        "Understanding the slope's significance is crucial for interpreting the strength and nature of the relationship between variables in regression analysis, as well as for making accurate predictions based on the model."
      ],
      "metadata": {
        "id": "Th9bg8PProbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "In regression analysis, the intercept (often denoted as\n",
        "ùõΩ\n",
        "0\n",
        "‚Äã) represents the expected value of the dependent variable (\n",
        "ùëå\n",
        ") when all independent variables (\n",
        "ùëã\n",
        ") are equal to zero. This parameter provides a baseline from which the effects of the independent variables are measured.\n",
        "\n",
        "Contextual Significance of the Intercept:\n",
        "\n",
        "Meaningfulness: The interpretability of the intercept depends on whether a zero value for the independent variables is within the scope of the data and has practical relevance. For instance, if\n",
        "ùëã\n",
        "represents temperature in degrees Celsius, an intercept would indicate the expected value of\n",
        "ùëå at 0¬∞C. However, if\n",
        "ùëã\n",
        "represents a variable like age, where a value of zero may not be observed or meaningful, the intercept becomes less interpretable.\n",
        "\n",
        "Baseline Level: The intercept serves as a baseline, providing the starting point for the regression line on the Y-axis. It reflects the portion of the dependent variable that is not influenced by the independent variables included in the model.\n",
        "\n",
        "Considerations:\n",
        "\n",
        "Centering Variables: When zero is not a meaningful value for an independent variable, centering the variable by subtracting its mean can make the intercept more interpretable. This adjustment shifts the reference point, allowing the intercept to represent the expected value of\n",
        "ùëå\n",
        " when\n",
        "ùëã\n",
        " is at its mean.\n",
        "\n",
        "Multiple Regression: In models with multiple predictors, the intercept represents the expected value of\n",
        "ùëå\n",
        " when all\n",
        "ùëã\n",
        " variables are zero simultaneously. If this combination is unrealistic, the intercept may lack practical interpretation.\n",
        "\n",
        "Understanding the role of the intercept is crucial for accurately interpreting regression models and the relationships between variables."
      ],
      "metadata": {
        "id": "gh_i5pgQsgnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "\n",
        "Linearity Assumption: R¬≤ presumes a linear relationship between the independent and dependent variables. If the actual relationship is nonlinear, R¬≤ may not accurately reflect the model's explanatory power.\n",
        "\n",
        "Sensitivity to Outliers: Outliers can disproportionately influence R¬≤, leading to misleadingly high or low values that do not accurately represent the model's fit for the majority of the data.\n",
        "\n",
        "Correlation Does Not Imply Causation: A high R¬≤ indicates a strong association but does not establish a causal relationship between variables. Other statistical analyses are necessary to infer causation.\n",
        "\n",
        "Addition of Irrelevant Variables: Including additional independent variables, even if they are irrelevant, can artificially inflate R¬≤, giving a false impression of improved model performance.\n",
        "\n",
        "Lack of Predictive Accuracy: A high R¬≤ does not guarantee that the model will make accurate predictions on new, unseen data. The model may fit the training data well but perform poorly in practice."
      ],
      "metadata": {
        "id": "eLl7uJLrtU5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.  How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "In regression analysis, a large standard error for a regression coefficient indicates that the estimate of that coefficient is imprecise. This imprecision suggests that the corresponding predictor variable may not have a reliable or significant association with the dependent variable.\n",
        "\n",
        "Implications of a Large Standard Error:\n",
        "\n",
        "Statistical Significance: A large standard error relative to the coefficient's magnitude can lead to a low t-statistic, implying that the coefficient may not be statistically significant. This means we cannot confidently assert that the predictor variable has an effect on the dependent variable.\n",
        "\n",
        "Confidence Intervals: Larger standard errors result in wider confidence intervals for the coefficient, indicating greater uncertainty about the true value of the parameter.\n",
        "\n",
        "Potential Causes:\n",
        "\n",
        "Multicollinearity: High correlation among predictor variables can inflate standard errors, making it difficult to isolate the individual effect of each predictor.\n",
        "WIKIPEDIA\n",
        "\n",
        "Insufficient Data: A small sample size or limited variability in the data can lead to large standard errors, as there is less information available to accurately estimate the coefficient.\n",
        "\n",
        "Model Specification: Omitting relevant variables or including irrelevant ones can affect the precision of coefficient estimates, potentially increasing standard errors."
      ],
      "metadata": {
        "id": "zxXMrXUltl-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "A common method to detect heteroscedasticity is by examining a residuals versus fitted values plot. In this scatter plot, the residuals are plotted on the y-axis, and the fitted (predicted) values are on the x-axis. In the absence of heteroscedasticity (a condition known as homoscedasticity), the residuals should be randomly dispersed around the horizontal axis, forming a horizontal band. However, if heteroscedasticity is present, the plot may exhibit patterns such as:\n",
        "\n",
        "Fan or Cone Shape: The spread of the residuals increases or decreases with the fitted values, resembling a fan or cone.\n",
        "\n",
        "Systematic Patterns: Any systematic structure or pattern in the spread of residuals indicates non-constant variance.\n",
        "\n",
        "Ignoring heteroscedasticity can lead to several issues:\n",
        "\n",
        "Inefficient Estimates: While heteroscedasticity does not cause bias in the coefficient estimates, it reduces their efficiency, leading to less precise estimates.\n",
        "\n",
        "Invalid Inferences: Standard errors of the coefficients may be underestimated or overestimated, resulting in misleading p-values and confidence intervals. This misestimation can cause incorrect conclusions about the significance of predictors.\n",
        "\n",
        "Reliability of Predictions: The presence of heteroscedasticity can affect the reliability of the model's predictions, especially for values of the independent variables where the variance of the residuals is large."
      ],
      "metadata": {
        "id": "ZX8TGE_-t6xm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.  What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?\n",
        "\n",
        "In multiple linear regression, R¬≤ measures the proportion of variance in the dependent variable explained by the independent variables. However, R¬≤ always increases or remains the same when additional predictors are added, regardless of their relevance. To account for this, Adjusted R¬≤ adjusts for the number of predictors in the model, providing a more accurate measure of model fit.\n",
        "\n",
        "If a model exhibits a high R¬≤ but a low Adjusted R¬≤, it suggests that the added predictors do not contribute meaningfully to explaining the variance in the dependent variable. This discrepancy indicates that the model may include irrelevant or redundant predictors, leading to overfitting. Overfitting occurs when a model captures noise rather than the underlying data pattern, resulting in poor generalization to new data.\n",
        "\n",
        "To address this issue, consider simplifying the model by removing predictors that do not significantly contribute to explaining the variance in the dependent variable. This approach can improve the model's generalizability and provide a more accurate representation of the underlying relationships."
      ],
      "metadata": {
        "id": "GXlNECJouVIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "In multiple linear regression, scaling (standardizing) variables is important for several reasons:\n",
        "\n",
        "Interpretation of Coefficients: Scaling can make it easier to interpret regression coefficients, especially when predictor variables are on different scales. By standardizing variables, the coefficients represent the change in the dependent variable for a one standard deviation change in the predictor, facilitating comparison across predictors.\n",
        "\n",
        "Numerical Stability: When predictor variables have vastly different scales, it can lead to numerical instability in the computation of regression coefficients. Scaling helps mitigate this issue by bringing all variables to a comparable range.\n",
        "\n",
        "Multicollinearity Detection: Scaling does not affect the detection of multicollinearity, as the Variance Inflation Factor (VIF) is invariant to the scaling of variables.\n"
      ],
      "metadata": {
        "id": "Oah1wvm6aI9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.  What is polynomial regression?\n",
        "\n",
        "Polynomial regression is a form of regression analysis that models the relationship between the independent variable\n",
        "ùë•\n",
        "and the dependent variable\n",
        "ùë¶ as an\n",
        "ùëõ\n",
        "th degree polynomial. This approach is particularly useful when the data exhibits a nonlinear relationship that cannot be adequately captured by a simple linear model."
      ],
      "metadata": {
        "id": "QJXkWu0nanEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.  How does polynomial regression differ from linear regression?\n",
        "\n",
        "In regression analysis, both linear and polynomial regression aim to model the relationship between independent and dependent variables, but they differ in how they represent this relationship.\n",
        "\n",
        "Model Complexity:\n",
        "\n",
        "Linear Regression: Assumes a straight-line relationship between variables.\n",
        "\n",
        "Polynomial Regression: Captures more complex, nonlinear relationships by including higher-degree terms of the independent variable.\n",
        "\n",
        "Flexibility:\n",
        "\n",
        "Linear Regression: Limited to modeling linear trends.\n",
        "\n",
        "Polynomial Regression: More flexible, capable of fitting a wider range of data patterns, including curves.\n",
        "\n",
        "Risk of Overfitting:\n",
        "\n",
        "Linear Regression: Less prone to overfitting due to its simplicity.\n",
        "\n",
        "Polynomial Regression: Higher risk of overfitting, especially with high-degree polynomials, as the model may capture noise in the data rather than the underlying trend."
      ],
      "metadata": {
        "id": "xhHbfvOybCIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?\n",
        "\n",
        "Polynomial regression is employed when the relationship between the independent and dependent variables is nonlinear and cannot be adequately captured by a simple linear model.\n",
        "\n",
        "Finance: Modeling stock price movements and market trends that exhibit nonlinear patterns.\n",
        "\n",
        "Healthcare: Predicting growth patterns, such as tumor progression or the spread of diseases within a population.\n",
        "\n",
        "Manufacturing: Analyzing system performance curves to optimize machine operations and predict material behavior under varying conditions.\n",
        "\n",
        "Environmental Science: Studying the relationship between environmental factors and ecological responses, such as the effect of temperature on crop yields.\n",
        "\n",
        "Medicine: Modeling the concentration of drugs in the body over time to understand pharmacokinetics.\n",
        "\n",
        "Epidemiology: Estimating the death toll or infection rates during disease outbreaks by fitting curves to the data.\n"
      ],
      "metadata": {
        "id": "RsvsfGWHcEiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. What is the general equation for polynomial regression?\n",
        "\n",
        "In polynomial regression, the relationship between the dependent variable\n",
        "y and the independent variable\n",
        "x is modeled as an\n",
        "n-th degree polynomial. The general form of the polynomial regression equation is:\n",
        "\n",
        "y=Œ≤\n",
        "0\n",
        "‚Äã\n",
        " +Œ≤\n",
        "1\n",
        "‚Äã\n",
        " x+Œ≤\n",
        "2\n",
        "‚Äã\n",
        " x\n",
        "2\n",
        " +Œ≤\n",
        "3\n",
        "‚Äã\n",
        " x\n",
        "3\n",
        " +‚ãØ+Œ≤\n",
        "n\n",
        "‚Äã\n",
        " x\n",
        "n\n",
        " +Œµ\n",
        "\n",
        "Where:\n",
        "\n",
        "y: Dependent variable\n",
        "\n",
        "x: Independent variable\n",
        "\n",
        "Œ≤\n",
        "0\n",
        "‚Äã\n",
        " ,Œ≤\n",
        "1\n",
        "‚Äã\n",
        " ,‚Ä¶,Œ≤\n",
        "n\n",
        "‚Äã\n",
        " : Coefficients of the polynomial terms\n",
        "\n",
        "Œµ: Error term"
      ],
      "metadata": {
        "id": "Hp9Fk8ebdR1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Yes, polynomial regression can be extended to handle multiple independent variables, a technique known as multivariate polynomial regression. This approach models the relationship between a dependent variable and multiple independent variables by incorporating polynomial terms of the predictors, allowing for the capture of complex, nonlinear interactions among them."
      ],
      "metadata": {
        "id": "pKAiyueld-uU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. What are the limitations of polynomial regression?\n",
        "\n",
        "Overfitting: As the degree of the polynomial increases, the model can become overly complex, capturing noise in the data rather than the underlying trend. This leads to poor generalization to new data.\n",
        "\n",
        "Extrapolation Issues: Polynomial models can behave unpredictably outside the range of the observed data, making them unreliable for extrapolation.\n",
        "\n",
        "Sensitivity to Outliers: Polynomials are sensitive to outliers; even a single outlier can significantly distort the model, leading to misleading results.\n",
        "\n",
        "Multicollinearity: Including higher-degree polynomial terms can introduce multicollinearity, where predictor variables become highly correlated. This can destabilize the estimation of coefficients and affect the model's interpretability.\n",
        "\n",
        "Interpretability: As the polynomial degree increases, the model becomes more complex, making it difficult to interpret the influence of individual predictors on the response variable."
      ],
      "metadata": {
        "id": "gfuSFyTpeMrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "Cross-Validation: This technique involves partitioning the dataset into multiple subsets, training the model on some subsets, and testing it on the remaining ones. By assessing the model's performance across different subsets, cross-validation helps identify the polynomial degree that minimizes prediction error and reduces overfitting.\n",
        "\n",
        "Adjusted R-squared (\n",
        "R\n",
        "adj\n",
        "2\n",
        "‚Äã\n",
        " ): Unlike the regular\n",
        "R\n",
        "2 , which can increase with the addition of more predictors,\n",
        "R\n",
        "adj\n",
        "2\n",
        "‚Äã adjusts for the number of predictors in the model. A higher\n",
        "R\n",
        "adj\n",
        "2\n",
        "  indicates a better fit, accounting for model complexity.\n",
        "\n",
        "Residual Analysis: Examining residual plots can reveal patterns indicating model inadequacies. A well-fitting model should have residuals randomly scattered around zero without discernible patterns. Systematic patterns may suggest the need for a different model or transformation."
      ],
      "metadata": {
        "id": "LgJEjDLbekFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Why is visualization important in polynomial regression?\n",
        "\n",
        "Assessing Model Fit: By plotting the data alongside the polynomial regression curve, you can visually evaluate how well the model captures the underlying trend. This helps in identifying whether the chosen polynomial degree appropriately represents the data's complexity.\n",
        "\n",
        "Detecting Overfitting: Visualization allows you to observe if the polynomial curve excessively oscillates or closely follows every data point, indicating overfitting. Such patterns suggest that the model may be too complex and might not generalize well to new data.\n",
        "\n",
        "Identifying Residual Patterns: Plotting residuals (the differences between observed and predicted values) can reveal systematic patterns or randomness. Randomly scattered residuals suggest a good fit, while patterns may indicate model inadequacies or the need for a different modeling approach.\n",
        "\n",
        "Evaluating Polynomial Degree: Visualization helps in determining the appropriate polynomial degree by showing how the model's complexity affects the fit. It aids in balancing underfitting and overfitting, ensuring the model captures the data's structure without unnecessary complexity."
      ],
      "metadata": {
        "id": "dIhzyRhpfr86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31.  How is polynomial regression implemented in Python?\n",
        "\n",
        "Import Necessary Libraries:"
      ],
      "metadata": {
        "id": "YWONSvg4g8pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "sRa78BX8hMvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the Data:"
      ],
      "metadata": {
        "id": "HqBGd1cZhQJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([1, 4, 9, 16, 25])"
      ],
      "metadata": {
        "id": "-NrHnYnOhTFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Features:"
      ],
      "metadata": {
        "id": "4h273fBqhWu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)"
      ],
      "metadata": {
        "id": "GNeL4H3qhbE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the Model:"
      ],
      "metadata": {
        "id": "DzsqOI_phfU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)"
      ],
      "metadata": {
        "id": "lrhwvHxjhiXW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0dc5c44f-6b3a-46d3-e5d0-9dbec4ae2807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions:"
      ],
      "metadata": {
        "id": "CzP1UKdHhmUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_poly)"
      ],
      "metadata": {
        "id": "ocnzo2CihrAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the Results:"
      ],
      "metadata": {
        "id": "kIOXrI3ihsZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X, y, color='blue', label='Original Data')\n",
        "plt.plot(X, y_pred, color='red', label='Polynomial Fit')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v94wUPpXhvEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "ca7420c3-9cc1-4d83-c1fd-84d48669e2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}